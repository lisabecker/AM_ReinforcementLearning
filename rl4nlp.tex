\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[round]{natbib}
%\usepackage[style=authoryear,sorting=ynt]{biblatex}
\bibliographystyle{plainnat}
\usepackage[hyperref]{acl2018}
\usepackage{times}
\usepackage{latexsym}
\usepackage{url}
\usepackage{array}
\usepackage{graphicx}
\usepackage[font=small,labelfont=bf]{caption}
\graphicspath{ {./img/} } 
\pagestyle{plain}

\title{{\LARGE Reinforcement Learning for Natural Language Processing}\\[1.5mm]
{\large Final paper: Literature Review Article}\\[1.5mm]} 
\author{Author: Lisa Becker (775242) } 

\begin{document}
\maketitle
\section{Abstract}


\section{Introduction}
In 2016, DeepMind put Reinforcement Learning (RL) in the spotlights by developing AlphaGo \citep{alphago}. Since then, RL has made many advantages in various subdomains, one of them being Natural Language Processing (NLP). As stated in \citet{ijcai2019}, both domains influence each other. While we can gain new linguistic knowledge by getting insight into how RL agents deal with language, NLP can be used to enhance RL models. Since RL in NLP started to become more popular, various subdomains and applications emerged, such as Article summarization, Question Generation and Answering, Dialogue generation, Dialogue Systems, Machine Translation, Text generation.

\section{Background}

\section{Current Use of NLP in RL}


\section{Trends for NLP in RL}
Dialogue 
Most RL models still utilise the the policy gradient REINFORCE algorithm or Deep Q Learning as their method.

\section{Problems for NLP in RL}
Research faces a few problems regarding the application of RL in NLP. 

While most research focuses on the reward function in order to maximize the agent's expected long-term reward, \citet{madureira2020} discussed the importance of state in RL for NLP. While the formalisation of the state and its properties depends on the value and reward function, 

\subsection{Data and Language}
\textbf{Anglocentrism} dominates most research fields, with NLP and more specifically RL being no exception. This is due to English continuing to be the main language in which research is written and communicated. While this is not a problem per se, it compels many researchers to also use English as their main language for conducting their experiments due to available data and funding for English research. This homogeneity is a common property of a young research field but still needs to be overcome by broadening up to other languages. This is not only important in terms of ethical diversity but also a necessary step to achieve overall application of RL across languages. \\\\
\textbf{Data} is not only limited in language but also in size and diversity. Since RL models tend to improve by larger corpora, it becomes exponentially difficult to provide datasets of sufficient quality by increase of size. Consequently, many studies are performed on the same datasets.


\section{Conclusion}
As  \citet{ijcai2019} stated, "approaches combining language and RL will find applications as wide-ranging as autonomous vehicles, virtual assistants and household robots". While RL in NLP has made some advances, it is still far from being successfully exploited in Life Sciences. More careful research, especially in regard to the limitations and ethical implications, has to be conducted in order to model agents who can reliably applied to everyday lifes. 

\newpage
\bibliography{bib}

\end{document}